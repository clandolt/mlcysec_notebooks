{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22007f23",
   "metadata": {},
   "source": [
    "# Tutorial 2.2: Deep Learning based IDS\n",
    "\n",
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Under_Construction&color=orange)\n",
    "\n",
    "\n",
    "**Open notebook on:** \n",
    "[![View filled on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/clandolt/mlcysec_notebooks/blob/main/source/tutorial_notebooks/tutorial2_anomaly_detection/tutorial2_anomaly_detection.ipynb)\n",
    "[![Open filled In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/clandolt/mlcysec_notebooks/blob/main/source/tutorial_notebooks/tutorial2_anomaly_detection/tutorial2_anomaly_detection.ipynb)   \n",
    "**Author:** Christoph R. Landolt\n",
    "\n",
    "\n",
    "In modern cybersecurity, labeled attack data is often scarce or incomplete. Many attacks are unknown, rare, or stealthy (APT, ATA). Neural network-based unsupervised models, such as Variational Autoencoders (VAE) and One-Class Neural Networks (OC-NN), can learn the normal behavior of network traffic and flag deviations as anomalies. These approaches are particularly useful for intrusion detection, malware monitoring, and unusual user behavior detection.\n",
    "\n",
    "## Tutorial Objectives\n",
    "By the end of this tutorial, you will be able to:\n",
    "- Understand neural network approaches to anomaly detection.\n",
    "- Explain the mathematical formulation of VAE and OC-NN for anomaly detection.\n",
    "- Implement VAE and OC-NN using PyTorch.\n",
    "- Evaluate anomaly detection performance on the KDDCUP99 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355dc3ea",
   "metadata": {},
   "source": [
    "## Neural Network-Based Anomaly Detection in Cybersecurity\n",
    "Traditional anomaly detection algorithms, such as Isolation Forest or One-Class SVM, are effective for tabular data, but they can struggle with high-dimensional, complex, or non-linear feature distributions. Neural networks provide:\n",
    "\n",
    "- **Flexibility:** Can model complex, non-linear relationships.\n",
    "- **Feature learning:** Automatically extract latent representations.\n",
    "- **Probabilistic modeling:** In the case of VAE, estimate the likelihood of each observation.\n",
    "\n",
    "## Variational Autoencoder (VAE)\n",
    "\n",
    "A **Variational Autoencoder (VAE)** is a *generative probabilistic model* that learns a continuous latent representation of data.  \n",
    "It assumes that each observation $x$ is generated from a latent variable $z$ through a conditional distribution $p_\\theta(x \\mid z)$.\n",
    "\n",
    "### Probabilistic Model\n",
    "\n",
    "The data likelihood is defined as:\n",
    "$$\n",
    "p_\\theta(x) = \\int p_\\theta(x \\mid z) \\, p(z) \\, dz\n",
    "$$\n",
    "\n",
    "where the prior over latent variables is a standard normal distribution:\n",
    "$$\n",
    "p(z) = \\mathcal{N}(0, I)\n",
    "$$\n",
    "\n",
    "Since the true posterior $p_\\theta(z \\mid x)$ is intractable, the VAE introduces an approximate posterior (encoder) $q_\\phi(z \\mid x)$ to estimate it.\n",
    "\n",
    "### Training Objective: Evidence Lower Bound (ELBO)\n",
    "\n",
    "The model is trained by maximizing the **Evidence Lower Bound (ELBO)**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\phi; x)\n",
    "= \n",
    "\\mathbb{E}_{q_\\phi(z \\mid x)} [ \\log p_\\theta(x \\mid z) ]\n",
    "-\n",
    "D_{\\mathrm{KL}}(q_\\phi(z \\mid x) \\, \\| \\, p(z))\n",
    "$$\n",
    "\n",
    "- The **first term** is the *reconstruction likelihood*, encouraging accurate reconstruction of inputs.  \n",
    "- The **second term** is the *Kullback–Leibler (KL) divergence*, acting as a regularizer to keep the latent space close to the prior $\\mathcal{N}(0, I)$.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "The VAE consists of two main components:\n",
    "\n",
    "- **Encoder (Inference network)**: learns to map data $x$ into a latent representation $z$  \n",
    "  $q_\\phi(z \\mid x) = \\mathcal{N}(\\mu(x), \\sigma^2(x) I)$\n",
    "  \n",
    "- **Decoder (Generative network)**: reconstructs data from the latent representation  \n",
    "  $p_\\theta(x \\mid z) = \\mathcal{N}(f_\\theta(z), \\sigma^2 I)$\n",
    "\n",
    "### Anomaly Detection with VAE\n",
    "\n",
    "For anomaly detection, the VAE is trained **only on normal samples** to capture the manifold of legitimate data.  \n",
    "At test time, we compute the **reconstruction error** for each input:\n",
    "\n",
    "$$\n",
    "\\text{Error}(x) = \\| x - \\hat{x} \\|^2\n",
    "$$\n",
    "\n",
    "where $\\hat{x} = f_\\theta(z)$ is the reconstructed input.\n",
    "\n",
    "- **Low reconstruction error** → sample lies on the learned manifold → likely normal  \n",
    "- **High reconstruction error** → sample deviates from normal behavior → potential anomaly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677dae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea78c4",
   "metadata": {},
   "source": [
    "#### Step 1: Load and Explore the KDDCUP99 Dataset\n",
    "\n",
    "\n",
    "First, we'll load the `SA` subset of the **KDDCUP99 dataset** to keep computation manageable. Then we'll explore and visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22304fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10065 datapoints with 338 anomalies (3.36%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ### Step 1: Load and Explore the KDDCUP99 Dataset\n",
    "X, y = datasets.fetch_kddcup99(\n",
    "    subset=\"SA\",             # Use the 'SA' subset (smaller sample)\n",
    "    percent10=True,          # Use 10% of the full dataset for efficiency\n",
    "    random_state=42,         # Ensure reproducibility\n",
    "    return_X_y=True,         # Return data and labels separately\n",
    "    as_frame=True            # Load as pandas DataFrame\n",
    ")\n",
    "\n",
    "# Convert binary label: 1 = attack, 0 = normal\n",
    "y = (y != b\"normal.\").astype(np.int32)\n",
    "\n",
    "# Take only 10% of the data for quick demonstration\n",
    "X, _, y, _ = train_test_split(X, y, train_size=0.1, stratify=y, random_state=42)\n",
    "\n",
    "# Display dataset stats\n",
    "n_samples, anomaly_frac = X.shape[0], y.mean()\n",
    "print(f\"{n_samples} datapoints with {y.sum()} anomalies ({anomaly_frac:.02%})\")\n",
    "\n",
    "# Plot label distribution\n",
    "plt.hist(y, bins=[-0.5, 0.5, 1.5], edgecolor='black')\n",
    "plt.xticks([0, 1], ['Normal', 'Attack'])\n",
    "plt.title('Histogram of Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37007c92",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- The histogram provides a visual overview of **class imbalance** in the dataset. In the KDDCUP99 subset, normal traffic far outnumbers attack events.  \n",
    "- This imbalance is **typical in cybersecurity datasets**, reflecting real-world conditions where attacks are rare relative to benign activity.  \n",
    "- From a theoretical perspective, Intrusion Detection Systems (IDS) face two main challenges in such imbalanced environments:\n",
    "  1. **Scarcity of labeled attack data**: Many attack patterns are unknown, costly to label, or represent vulnerabilities not yet exploited.  \n",
    "  2. **Diversity of attack types**: Attacks can range from common automated probes to sophisticated Advanced Persistent Threats (APT) and Advanced Targeted Attacks (ATA), which occur rarely and blend into normal traffic.\n",
    "- Therefore, the observed class imbalance in the histogram **justifies the use of unsupervised anomaly detection models** (such as Isolation Forest), which do not rely on balanced labeled datasets but exploit the intrinsic structure of the data to detect deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb8be6",
   "metadata": {},
   "source": [
    "#### Step 2: Data Preprocessing\n",
    "\n",
    "Before training, categorical (non-numeric) features must be converted into numerical form.\n",
    "We’ll use **one-hot encoding** with `pandas.get_dummies()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c394c176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape after encoding: (10065, 6536)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_0</th>\n",
       "      <th>duration_1</th>\n",
       "      <th>duration_2</th>\n",
       "      <th>duration_3</th>\n",
       "      <th>duration_4</th>\n",
       "      <th>duration_5</th>\n",
       "      <th>duration_6</th>\n",
       "      <th>duration_7</th>\n",
       "      <th>duration_8</th>\n",
       "      <th>duration_9</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_rerror_rate_0.91</th>\n",
       "      <th>dst_host_srv_rerror_rate_0.92</th>\n",
       "      <th>dst_host_srv_rerror_rate_0.93</th>\n",
       "      <th>dst_host_srv_rerror_rate_0.94</th>\n",
       "      <th>dst_host_srv_rerror_rate_0.95</th>\n",
       "      <th>dst_host_srv_rerror_rate_0.96</th>\n",
       "      <th>dst_host_srv_rerror_rate_0.97</th>\n",
       "      <th>dst_host_srv_rerror_rate_0.98</th>\n",
       "      <th>dst_host_srv_rerror_rate_0.99</th>\n",
       "      <th>dst_host_srv_rerror_rate_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26890</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35471</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37027</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80164</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73649</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration_0  duration_1  duration_2  duration_3  duration_4  duration_5  \\\n",
       "26890        True       False       False       False       False       False   \n",
       "35471       False        True       False       False       False       False   \n",
       "37027        True       False       False       False       False       False   \n",
       "80164       False       False       False       False       False       False   \n",
       "73649        True       False       False       False       False       False   \n",
       "\n",
       "       duration_6  duration_7  duration_8  duration_9  ...  \\\n",
       "26890       False       False       False       False  ...   \n",
       "35471       False       False       False       False  ...   \n",
       "37027       False       False       False       False  ...   \n",
       "80164       False       False       False       False  ...   \n",
       "73649       False       False       False       False  ...   \n",
       "\n",
       "       dst_host_srv_rerror_rate_0.91  dst_host_srv_rerror_rate_0.92  \\\n",
       "26890                          False                          False   \n",
       "35471                          False                          False   \n",
       "37027                          False                          False   \n",
       "80164                          False                          False   \n",
       "73649                          False                          False   \n",
       "\n",
       "       dst_host_srv_rerror_rate_0.93  dst_host_srv_rerror_rate_0.94  \\\n",
       "26890                          False                          False   \n",
       "35471                          False                          False   \n",
       "37027                          False                          False   \n",
       "80164                          False                          False   \n",
       "73649                          False                          False   \n",
       "\n",
       "       dst_host_srv_rerror_rate_0.95  dst_host_srv_rerror_rate_0.96  \\\n",
       "26890                          False                          False   \n",
       "35471                          False                          False   \n",
       "37027                          False                          False   \n",
       "80164                          False                          False   \n",
       "73649                          False                          False   \n",
       "\n",
       "       dst_host_srv_rerror_rate_0.97  dst_host_srv_rerror_rate_0.98  \\\n",
       "26890                          False                          False   \n",
       "35471                          False                          False   \n",
       "37027                          False                          False   \n",
       "80164                          False                          False   \n",
       "73649                          False                          False   \n",
       "\n",
       "       dst_host_srv_rerror_rate_0.99  dst_host_srv_rerror_rate_1.0  \n",
       "26890                          False                         False  \n",
       "35471                          False                         False  \n",
       "37027                          False                         False  \n",
       "80164                          False                         False  \n",
       "73649                          False                         False  \n",
       "\n",
       "[5 rows x 6536 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variables to numerical format\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "print(f\"Feature matrix shape after encoding: {X.shape}\")\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343181d",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- Many columns in KDDCUP99 are categorical (e.g., protocol type, service, flag).\n",
    "- One-hot encoding converts these categories into binary vectors, making them compatible with ML models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969f7c9",
   "metadata": {},
   "source": [
    "### Step 3: Train-Test Split\n",
    "\n",
    "We split the dataset into **training (80%)** and **testing (20%)** subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08365fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training only on normal points: 7784 samples\n",
      "Testing samples: 2013\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Keep only normal samples in the training set\n",
    "X_train = X_train[y_train == 0]\n",
    "print(f\"Training only on normal points: {len(X_train)} samples\")\n",
    "print(\"Testing samples:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bafbd7",
   "metadata": {},
   "source": [
    "#### Step 4: Variational Autoencoder (VAE) Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83355cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "input_dim = X_train.shape[1]\n",
    "latent_dim = 10\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc_mu = nn.Linear(64, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64, latent_dim)\n",
    "        self.fc2 = nn.Linear(latent_dim, 64)\n",
    "        self.fc3 = nn.Linear(64, input_dim)\n",
    "    def encode(self, x):\n",
    "        h = torch.relu(self.fc1(x))\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    def decode(self, z):\n",
    "        h = torch.relu(self.fc2(z))\n",
    "        return self.fc3(h)\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    recon_loss = nn.MSELoss()(recon_x, x)\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kld\n",
    "\n",
    "vae = VAE(input_dim, latent_dim).to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "X_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674bbb3f",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be739b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0370\n",
      "Epoch 20, Loss: 0.0228\n",
      "Epoch 30, Loss: 0.0158\n",
      "Epoch 40, Loss: 0.0117\n",
      "Epoch 50, Loss: 0.0092\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    recon, mu, logvar = vae(X_tensor)\n",
    "    loss = vae_loss(recon, X_tensor, mu, logvar)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094a5af",
   "metadata": {},
   "source": [
    "Compute reconstruction-based anomaly scores:\n",
    "High reconstruction error → likely anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "336b9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    recon, _, _ = vae(X_tensor)\n",
    "errors = torch.mean((X_tensor - recon)**2, dim=1)\n",
    "anomaly_scores_vae = errors.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c9667",
   "metadata": {},
   "source": [
    "## One-Class Neural Network (OC-NN)\n",
    "\n",
    "The **One-Class Neural Network (OC-NN)** is a neural extension of the traditional **One-Class SVM (OC-SVM)**.  \n",
    "Its goal is to learn a compact representation of *normal* data in a latent feature space, effectively separating it from potential anomalies.\n",
    "\n",
    "**Idea:**\n",
    "Instead of relying on a predefined kernel as in OC-SVM, OC-NN uses a neural network $f_\\theta(x)$ to **map input data into a latent space** where normal samples are concentrated around the origin (or a compact region).\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "Let $f_\\theta(x)$ denote the neural network output for input $x$.  \n",
    "The OC-NN minimizes the distance of normal samples from a learned boundary (radius $r$) while allowing a small fraction $\\nu$ of samples to fall outside:\n",
    "\n",
    "$$\n",
    "\\min_\\theta \\; \\frac{1}{n} \\sum_{i=1}^n \\max(0, f_\\theta(x_i) - r)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $r$ is the *radius* (determined from the $\\nu$-th quantile of outputs)\n",
    "- $\\nu \\in (0, 1)$ approximates the *expected fraction of anomalies*\n",
    "\n",
    "### Intuition\n",
    "\n",
    "- **Normal samples:** mapped close to the origin (or within the radius $r$)  \n",
    "- **Anomalous samples:** lie outside this compact region, with higher output scores\n",
    "\n",
    "Thus, the network learns a **boundary around normal data**, similar to the hypersphere used in One-Class SVM.\n",
    "\n",
    "### Anomaly Scoring\n",
    "\n",
    "After training, the **anomaly score** for a new input $x$ is given by:\n",
    "\n",
    "$$\n",
    "s(x) = f_\\theta(x) - r\n",
    "$$\n",
    "\n",
    "- $s(x) \\leq 0$ → sample lies inside the normal region → **normal**\n",
    "- $s(x) > 0$ → sample lies outside the region → **anomalous**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26999776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 1)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def ocnn_loss(outputs, nu=0.05):\n",
    "    dist = outputs.squeeze()\n",
    "    r = torch.quantile(dist, nu)\n",
    "    return torch.mean(torch.max(torch.zeros_like(dist), dist - r))\n",
    "\n",
    "ocnn = OCNN(input_dim).to(device)\n",
    "optimizer = optim.Adam(ocnn.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dabe09",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "206d3c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, OC-NN Loss: 0.0043\n",
      "Epoch 20, OC-NN Loss: 0.0027\n",
      "Epoch 30, OC-NN Loss: 0.0026\n",
      "Epoch 40, OC-NN Loss: 0.0018\n",
      "Epoch 50, OC-NN Loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ocnn(X_tensor)\n",
    "    loss = ocnn_loss(outputs, nu=0.04)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, OC-NN Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9687448",
   "metadata": {},
   "source": [
    "Anomaly Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fefa509",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocnn.eval()\n",
    "with torch.no_grad():\n",
    "    scores = ocnn(X_tensor).squeeze()\n",
    "anomaly_scores_ocnn = scores.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef322f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a4442",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[![Star our repository](https://img.shields.io/static/v1.svg?logo=star&label=⭐&message=Star%20Our%20Repository&color=yellow)](https://github.com/clandolt/mlcysec_notebooks/)  If you found this tutorial helpful, please **⭐ star our repository** to show your support.   \n",
    "[![Ask questions](https://img.shields.io/static/v1.svg?logo=star&label=❔&message=Ask%20Questions&color=9cf)](https://github.com/clandolt/mlcysec_notebooks/issues)  For any **questions**, **typos**, or **bugs**, kindly open an issue on GitHub — we appreciate your feedback!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3df3b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcysec25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
